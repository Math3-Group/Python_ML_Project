# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-U4hPRfI7DIVim06RZtSlFkTltUU_VKf
"""

#Alumnos: Lorenzo Quattrini, Mirko Santino Cuello.

'''
Antes de profundizar en el objetivo de este proyecto nos parece importante aclarar qué es el indicador Myers-Briggs,
para eso decidimos citar la siguiente definición:

"La evaluación MBTI identifica a las personas según uno de los 16 tipos de personalidad MBTI.
Cada tipo refleja cómo una persona prefiere naturalmente dirigir y recibir energía, asimilar información,
tomar decisiones y relacionarse con el mundo exterior. Conocer esto proporciona un marco sólido para comprender y
relacionarse con las personas."

Esta definición proviene del sitio oficial de la companía que desarrolló esta herramienta.
Para más información acá dejamos un enlace: https://www.themyersbriggs.com/
En caso de querer hacer el test que defina su personalidad, revisar el siguiente enlace: https://www.16personalities.com/es/test-de-personalidad

Sabido esto, nuestro objetivo final en este proyecto es el de desarrollar una red neuronal artificial (ANN)
que logre predecir el tipo de personalidad MBTI de un usuario a partir del análisis de sus
publicaciones escritas en foros. Estas publicaciones y usuarios provienen de un data-set proveniente de Kaggle.
'''

# Librerías
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Texto y preprocesamiento
import re
import string
import nltk
from nltk.corpus import stopwords

# Machine learning
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer

# Métricas
from sklearn.metrics import classification_report, confusion_matrix

# Keras
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.utils import to_categorical

sns.set(style="darkgrid")
nltk.download('stopwords')

#Carga de datos

df = pd.read_csv("mbti_1.csv")

#Limpieza de datos

def limpiar_texto(texto):
    texto = texto.lower()
    texto = re.sub(r'[^a-z\s]', '', texto)
    texto = re.sub(r'\s+', ' ', texto).strip()
    return texto
df['clean_posts'] = df['posts'].apply(limpiar_texto)

# Vectorizacion con TF-IDF
vectorizador = TfidfVectorizer(max_features=5000)
X = vectorizador.fit_transform(df['clean_posts'])

# Codificación de etiquetas
le = LabelEncoder()
y = le.fit_transform(df['type'])  # y va de 0 a 15
y_cat = to_categorical(y)

print(f"Clases MBTI detectadas: {list(le.classes_)}")

# Dividisión de datos
X_train, X_test, y_train_cat, y_test_cat = train_test_split(
    X, y_cat, test_size=0.2, random_state=42, stratify=y)

#Definición del modelo

def crear_modelo(input_dim, output_dim):
    modelo = Sequential([
        Dense(128, input_shape=(input_dim,), activation='relu'),
        Dropout(0.3),
        Dense(64, activation='relu'),
        Dropout(0.3),
        Dense(output_dim, activation='softmax')
    ])
    modelo.compile(optimizer='adam',
                   loss='categorical_crossentropy',
                   metrics=['accuracy'])
    return modelo

modelo = crear_modelo(X_train.shape[1], y_cat.shape[1])

#Entrenamiento
historial = modelo.fit(
    X_train.toarray(), y_train_cat,
    validation_data=(X_test.toarray(), y_test_cat),
    epochs=20,
    batch_size=64,
    verbose=1
)

#Evaluación
loss, acc = modelo.evaluate(X_test.toarray(), y_test_cat, verbose=0)
print(f"\n🔍 Evaluación en test:\nPérdida: {loss:.4f}\nPrecisión: {acc:.4f}")

#Visualización
def plot_metricas(historial):
    fig, axs = plt.subplots(1, 2, figsize=(14, 5))

    # Pérdida
    axs[0].plot(historial.history['loss'], label='Entrenamiento')
    axs[0].plot(historial.history['val_loss'], label='Validación')
    axs[0].set_title('Pérdida durante el entrenamiento')
    axs[0].set_xlabel('Épocas')
    axs[0].set_ylabel('Pérdida')
    axs[0].legend()

    # Precisión
    axs[1].plot(historial.history['accuracy'], label='Entrenamiento')
    axs[1].plot(historial.history['val_accuracy'], label='Validación')
    axs[1].set_title('Precisión durante el entrenamiento')
    axs[1].set_xlabel('Épocas')
    axs[1].set_ylabel('Precisión')
    axs[1].legend()

    plt.tight_layout()
    plt.show()

plot_metricas(historial)